New features:
- PopTorch now exposes PopART anchor options to choose how much data to return from a model. These
are passed into the model wrapper via |anchor_mode| options are Sum, All, Final and EveryN.
    All: Return a result for each batch.
    Sum: Return the sum of all the batches
    Final: Return the last batch.
    EveryN: Return every N batches. N is passed in as |anchor_return_period|

- Add support for batched LSTM and batch first

- An Options object can now be passed to poptorch.trainingModel / poptorch.inferenceModel to configure the session and select IPUs

- Add support for POPTORCH_IPU_MODEL and POPTORCH_WAIT_FOR_IPU environment variables.

- Adds support for the torch comparisons operations:
    torch.eq, torch.ge, torch.gt,
    torch.le, torch.lt, torch.max,
    torch.min, torch.ne, torch.isnan, torch.topk

    torch.min and torch.max only support (tensor, tensor) and (tensor) overloads. They do
    not support the (tensor, dim=, keepdim=) overload.

    torch.topk only supports sorted=False and Largest=True

- Automatically synchronise the weights back to the Host after using the IPU for training. (i.e no need to explicitly call copyWeightsToHost() anymore)

- Adds support for non-linear activations torch.nn.PReLU and torch.nn.Hardtanh

- Adds support for Adam optimizer.

- Adds support for half type models and inputs.

- Support for tensor.fill_, torch.full, torch.full_like

- Adds support for user provided custom operations. See PopART documentation for information on
  how to write them. They are exposed by `poptorch.custom_op` this takes in a list of
  input tensors, strings for the PopART op name and domain, the domain version, and
  a list of tensors the same shape and size as the expected output tensors. This is to
  ensure the pytorch trace remains valid as it traces on CPU so won't actually execute
  the operation when building the graph.

- Adds support for torch.nn.Conv1D / torch.nn.Conv2D / torch.nn.Conv3D

- Adds support for torch.nn.Upsample ('nearest' mode only)

- Adds support for tensor.size

- Adds support for torch.rand

- Adds support for torch.clamp

- Adds poptorch.DataLoader
